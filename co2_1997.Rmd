---
title: "Global $CO_{2}$ Emissions in 1997"
output: 
  pdf_document:
    latex_engine: pdflatex
    template: default
---

```{r setup, echo=FALSE, message=FALSE, error=FALSE, warning=FALSE}
library(tidyverse)
library(tsibble)
library(latex2exp)
library(ggplot2)
library(patchwork)
library(scatterplot3d)
library(forecast)
library(zoo)
library(fpp3)
library(stargazer)

theme_set(theme_minimal())
knitr::opts_chunk$set(dpi=1000)

df = as_tsibble(co2)

month = list()
year = list()
count = 1

for (val in df[['index']]) {
    val = as.character(df[['index']][count])
    
    #Get Month and Year from Index
    strs = strsplit(val,' ')[[1]]
    month[[count]] = strs[2]
    year[[count]] = strs[1]
    
    count = count + 1
    
}

#Store year and month results, case index as time index
df[['month']] = as.character(month)
df[['year']] = as.numeric(year)
df[['index1']] = c(1:dim(df)[1])
df[['month_int']] = df[['index1']] %% 12
df["month_int"][df["month_int"] == 0] = 12



#Quadratic and Log features of Time
for (num in 2:10){
    
    df[[paste('index',num,sep='')]] = as.numeric(df[['index1']]**num)
}

df[['log_index']] = log(df[['index1']])
```

\begin{center}
Naikaj Pandya, Amit Gattadahalli, Michael Golas, Austin Pitts  
\end{center}  

\vspace{1em}

\begin{center}
\textbf{Introduction}
\end{center}

In 1960, Charles Keeling in his seminal paper, *The Concentration and Isotopic Abundances of Carbon Dioxide in the Atmosphere* made two notable observations:  

1. That a seasonal variation in $CO_2$ concentrations was observed in the northern hemisphere, corresponding to the activity of land plants  
2. That at longer horizons, beyond one year, global concentrations of $CO_2$ have increased at a rate of 1.3 p.p.m. either from the combustion of fossil fuels or from factors tied to the seasonal variation, exceeding the counteracting oceanic effect removing $CO_2$ from the atmosphere.  

Keeling's analysis was conducted using data obtained from three gas analyzers, equipped to measure carbon dioxide concentrations continuously, located in Antarctica, Hawaii and California.  

Our goal, in 1994, is to validate Keeling's observations using data collected during the intervening years, measured using modern optical sensors at higher frequencies and report any observed changes to the rates of accumulated $CO_2$ in the atmosphere. Using these estimates we plan to extend our study and apply time-series modeling techniques to forecast the trends and variation in expected future $CO_2$ concentrations to provide bounds on the anticipated levels of $CO_2$. Since the amount of atmospheric $CO_2$ carries broad environmental and economic effects, our results are relevant to both environmental and policy researchers as crucial estimates to help guide mitigating courses of action within the appropriate time frames.  

\begin{center}
\textbf{CO2 Data}
\end{center}

We conduct a timeseries-analysis of atmospheric $CO_2$ levels using data collected by the NOAA. As stated, the goal is to examine any long-term trends and seasonal fluctuations in $CO_2$ levels.

The input data sourced from NOAA is collected using a $CO_2$ analyzer installed at Mauna Loa that uses a technique based on infrared absorption, wherein a sensor measures the magnitude of absorption of light circulating in an optical cavity.  Data is collected hourly, daily and monthly, we use the monthly average data for this analysis as our primary interest is devoted to long-term changes in $CO_2$ levels.  An important aspect of the measurements is the ongoing calibrations of the analyzer. The absorption by the instrument depends on the total amount of CO2, therefore the temperature and pressure in the instrument, as well as the flow rate, need to be measured and frequent calibrations performed with reference gas mixtures of known amounts of CO2-in-dry-air.  The intake lines are from the top of a 38 m tall tower next to the observatory, to avoid any influence on the measurements by human activities at the observatory. The difference of the ambient air measurements from the reference gas R0 are calculated, and these differences are used to calculate the true fraction CO2.

We begin with an exploratory analysis of the data guided by a few general observations apparent from visual inspection of the time-series:

- the data shows variation periodic in time
- the general level increases over time

One question is whether the variation remains constant independent of the level of $CO_2$. Analysis of variation around the trend-cycle reveals a persistent increase in the amplitude of the fluctuations.

```{r EDA, echo=FALSE, message=FALSE, fig.width=8, fig.height=2}
a <- as_tsibble(co2) %>% model(stl = STL()) %>% components() %>% select(season_year) %>% autoplot() + geom_abline(intercept=3, slope=0.00005, linetype="dashed", color = "red") + geom_abline(intercept=-3.2, slope=-0.00005, linetype="dashed", color = "red") + labs(title="Additive Decomposition")

b <- as_tsibble(log(co2)) %>% model(stl = STL()) %>% components() %>% select(season_year) %>% autoplot() + labs(title="Multiplicative Decomposition")

(a | b)
```
As we can see in the figures above, the Additive Decomposition flares outward. This leads us to conclude that the appropriate decomposition of the time-series into Trend, Seasonal, and Residual components is via Multiplicative Decomposition.

```{r decompo, echo=FALSE, message=FALSE, fig.width=8, fig.height=3}

as_tsibble(log(co2)) %>% model(stl = STL()) %>% components() %>% autoplot()

trend <- as_tsibble(log(co2)) %>% model(stl = STL()) %>% components() %>% select(trend)

```

Looking at the STL decomposition, although the long run growth rate of co2 is very low, approx. `r 12*100*summary(lm(trend ~ ., data=trend))$coefficients[2]`% per year, almost linear at the time-scale of observation, we note that the growth is highly statistically significant.

```{r, avg sd monthly co2 levels, echo=FALSE, results=FALSE, message=FALSE, warning=FALSE, fig.width=8, fig.height=2}
options(repr.plot.width = 20, repr.plot.height =10)

months = list()
means = list()
sds = list()

m_val = list('1'="Jan",
             '2'='Feb',
             '3'="Mar",
             '4'='Apr',
             '5'='May',
             '6'='Jun',
             '7'='Jul',
             '8'='Aug',
             '9'='Sep',
             '10'='Oct',
             '11'='Nov',
             '12'='Dec')
count = 1
for (val in unique(df[['month_int']])) {
    
    avg = mean(subset(df,month_int == val)[['value']])
    vol = sd(subset(df,month_int == val)[['value']])
    months[[count]] = m_val[[paste(val)]]
    means[[count]] = avg
    sds[[count]] = vol
    
    count = count + 1
    
}

months_df = data.frame(Index=1:length(months))
months_df[['Month']] = factor(as.character(months), 
                              levels = c('Jan','Feb','Mar','Apr','May','Jun','Jul','Aug','Sep','Oct','Nov','Dec'))
months_df[['Avg_CO2']] = as.numeric(means)
months_df[['SD_CO2']] = as.numeric(sds)

p1 = ggplot(months_df, aes(x = Month, y = Avg_CO2)) +
  geom_point(stat = 'identity') +

  labs(
    title = "Monthly Avg CO2 Levels",
    x = "Time",
    y = "Avg CO2 Levels"
  )

p2 = ggplot(months_df, aes(x = Month, y = SD_CO2)) +
  geom_point(stat = 'identity') +

  labs(
    title = "Monthly CO2 Level Volatility",
    x = "Time",
    y = "CO2 Level Volatility"
  )

p1 | p2
```

Finally, observing the month-to-month average CO2 levels and volatility gives us an idea of the seasonality in our data.

\begin{center}
\textbf{Linear Time Trend Model}
\end{center}

To setup our problem for validation we split our dataset into an in-sample train period spanning years prior to 1998 and post-1998 as the test period.

We fit linear, polynomial and quadratic models. We observe that the using a linear timeseries model the residuals exhibit a positive trend. This is also prevalent for the quadratic and polynomial models, however the magnitude of the trend is reduced. Our final model uses linear, quadratic, exponential and seasonal features.

```{r Linear time trend model part 1, echo=FALSE, results=FALSE, message=FALSE, warning=FALSE}
train = subset(df,year <= 1987)
test = subset(df, year > 1987)
```

```{r Linear time trend model part 2}
final_model = lm(value~index1+index2+log_index + month,df)
```

In our analysis we observed quality of fit, distribution of residuals and plots showing normality of residuals for each model.

We then used our final linear model to generate forecasts to the year 2022.

```{r Linear time trend model part 3, echo=FALSE, results=FALSE, message=FALSE, warning=FALSE, fig.width=8, fig.height=2}
BIC(final_model)

start_year = 1998
end_year = 2021
start_index = 469
month_count = 1

rows = data.frame()
count = 1
while (start_year < end_year){
    row = c(year = start_year,
               index1 = start_index,
               index2 = start_index**2, 
               index3 = start_index**3,
               log_index = log(start_index),
               month = m_val[[paste(month_count)]])
    rows = append(rows,row)
    count = count + 1
    start_index = start_index + 1
    month_count = month_count + 1
    if (month_count >= 13){
        month_count = 1
        start_year = start_year + 1
    }
}

rows = data.frame(t(matrix(rows,nrow = 6)))
colnames(rows) = c('year','index1','index2','index3','log_index','month')

for (col in c('index1','index2','index3','log_index')) {
    rows[[col]] = as.numeric(rows[[col]])
}

for (col in c('year','month')) {
    rows[[col]] = as.character(rows[[col]])
}

rows[['preds']] = predict(final_model,rows)

ggplot(rows) +
  geom_line(aes(x = index1, y = preds), color = 'blue') +

  labs(
    title = 'Forecasted CO2 Values',
    x = "Time",
    y = "CO2 Levels"
  )
```

\begin{center}
\textbf{ARIMA Time Series Model}
\end{center}

We developed an ARIMA model to fit to the series and generate forecasts to the year 2022.  The parameters of our model are chosen by cross-validation. We find that it is necessary to detrend the $CO_2$ Series such that it is stationary. To achieve this we use a linear model to detrend series as it captures the linear & nonlinear temporal and seasonal trends inherent in the data.

```{r ARIMA model}
df2 = df
df2[['diff_value']] = final_model$residuals
arima_model = arima(df2[['diff_value']], order=c(2,0,0))
```

While there is not enough room to provide all of these plots (see our Appendix if you would like to), in doing this process, we also 
- checked mean/variance of series over time to visually validate stationarity assumptions
- checked ACF/PACF plots
- performed a grid search to find P, Q values that minimize in sample BIC
- validated that our final model's residuals are white noise and approximately normally distributed

We also used our train and test set to measure our ARIMA model's performance, which turned out well.

```{r ARIMA model train, echo=FALSE, results=FALSE, message=FALSE, warning=FALSE, fig.width=8, fig.height=2}
df2[['resids']] = arima_model$residuals

vals = (df2[['diff_value']] - df2[['resids']])+final_model$fitted.values
df2[['final_arima_preds']] = vals
train_r2 = 1 - sum((df2[['value']] - vals)**2) / (var(df2[['value']])*dim(df2)[1])

ggplot(df2) +
  geom_line(aes(x = index1, y = value),color = 'blue') +
  geom_line(aes(x = index1, y = final_arima_preds),color = 'green') +
  labs(
    title = paste('True (Blue) vs Predicted (Green) C02 Levels Over Time, Train Set, R2 = ',train_r2),
    x = "Time",
    y = "CO2 Values"
  )
```


Similar to our linear model, we then used our final ARIMA model to also generate forecasts to the year 2022.

```{r Forecast ARIMA, echo=FALSE, results=FALSE, message=FALSE, warning=FALSE, fig.width=8, fig.height=2}
train_r2 = 1 - sum((arima_model$residuals**2)) / (var(df2[['diff_value']])*length(arima_model$residuals))

start_year = 1998
end_year = 2023
start_index = 469
month_count = 1

rows = data.frame()
count = 1
while (start_year < end_year){
    row = c(year = start_year,
               index1 = start_index,
               index2 = start_index**2, 
               index3 = start_index**3,
               log_index = log(start_index),
               month = m_val[[paste(month_count)]])
    rows = append(rows,row)
    count = count + 1
    start_index = start_index + 1
    month_count = month_count + 1
    if (month_count >= 13){
        month_count = 1
        start_year = start_year + 1
    }
}

rows = data.frame(t(matrix(rows,nrow = 6)))
colnames(rows) = c('year','index1','index2','index3','log_index','month')

for (col in c('index1','index2','index3','log_index')) {
    rows[[col]] = as.numeric(rows[[col]])
}

for (col in c('year','month')) {
    rows[[col]] = as.character(rows[[col]])
}

rows[['preds']] = predict(final_model,rows)
rows[['arima_preds']] = data.frame(forecast(arima_model,h=dim(rows)[1]))[['Point.Forecast']]
rows[['arima_lb']] = data.frame(forecast(arima_model,h=dim(rows)[1]))[['Lo.95']]
rows[['arima_ub']] = data.frame(forecast(arima_model,h=dim(rows)[1]))[['Hi.95']]

rows[['final_preds']] = rows[['preds']] + rows[['arima_preds']]

ggplot(rows, aes(x = index1, y = final_preds)) +
  geom_line() +

  labs(
    title = 'ARIMA CO2 Forecasts Over Time',
    x = "Time",
    y = "Forecasted CO2 Levels"
  )
```

\begin{center}
\textbf{Forecasting Atmospheric CO2 Growth}
\end{center}

We generate predictions for when atmospheric CO2 is expected to be at 420ppm and 500 ppm levels for the first and final times. Given errors observed from previous forecasts our hope is that our more modern models which utilize more sophisticated features will provide more accurate results of future $CO_2$ levels.

```{r Forecasting, echo=FALSE, results=FALSE, message=FALSE, warning=FALSE, fig.width=8, fig.height=2}
start_year = 1998
end_year = 2101
start_index = 469
month_count = 1

rows = data.frame()
count = 1
while (start_year < end_year){
    row = c(year = start_year,
               index1 = start_index,
               index2 = start_index**2, 
               index3 = start_index**3,
               log_index = log(start_index),
               month = m_val[[paste(month_count)]])
    rows = append(rows,row)
    count = count + 1
    start_index = start_index + 1
    month_count = month_count + 1
    if (month_count >= 13){
        month_count = 1
        start_year = start_year + 1
    }
}

rows = data.frame(t(matrix(rows,nrow = 6)))
colnames(rows) = c('year','index1','index2','index3','log_index','month')

for (col in c('index1','index2','index3','log_index')) {
    rows[[col]] = as.numeric(rows[[col]])
}

for (col in c('year','month')) {
    rows[[col]] = as.character(rows[[col]])
}

rows[['preds']] = predict(final_model,rows)
rows[['arima_preds']] = data.frame(forecast(arima_model,h=dim(rows)[1]))[['Point.Forecast']]
rows[['arima_lb']] = data.frame(forecast(arima_model,h=dim(rows)[1]))[['Lo.95']]
rows[['arima_ub']] = data.frame(forecast(arima_model,h=dim(rows)[1]))[['Hi.95']]

rows[['final_preds']] = rows[['preds']] + rows[['arima_preds']]

rows[['spot420']] = 420
rows[['spot500']] = 500

ggplot(rows) +
  geom_line(aes(x = index1, y = final_preds)) +
  geom_line(aes(x = index1, y = spot420), color = 'orange') + 
  geom_line(aes(x = index1, y = spot500), color = 'red') + 

  labs(
    title = 'ARIMA CO2 Forecasts Over Time',
    x = "Time",
    y = "Forecasted CO2 Levels"
  )
```
Based on this forcasting using our ARIMA model, our predictions are as follows:
- First and Final Time at 420, April 2024 - Oct 2026
- First and Final Time at 500, April 2055 - Nov 2056

We are fairly confident that these will be close to accurate predictions based on our analysis of our ARIMA model and its performance, but forecasting so far into the future means that our predictions will likely not be perfect.

\begin{center}
\textbf{Conclusion}
\end{center}

TODO - idk if we need this section, feel free to write something or remove the section all-together

\begin{center}
\textbf{Appendix}
\end{center}

While our final results are reported here, in our complete notebook (Github Folder: Notebook) we examine alternative models and go into further assessment of the models. The purpose of this background information is to show more of the process in how we reached the conclusions shown above.